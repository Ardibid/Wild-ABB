{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classifier Module\n",
    "\n",
    "ArdavanBidgoli <br />\n",
    "CMU School of Architecture <br />\n",
    "Robotic Plastering Project <br />\n",
    "Feedback-loop image classifier <br />\n",
    "Tested with/for: <br />\n",
    "Tensorflow 0.12.1 <br />\n",
    "OpenCV 3.2.0-dev <br />\n",
    "this code has been inspired by:\n",
    "https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/index.html?index=../../index#4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Tensorflow\n",
    "import tensorflow as tf\n",
    "# Importing matplotlib and Numpy for image processing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Import libraries for:\n",
    "# System read and write, Checking object types, Time keeping\n",
    "import sys\n",
    "import time\n",
    "from shutil import copyfile\n",
    "import cv2\n",
    "# import os.path methods for file manipulation on the drive\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join, exists\n",
    "\n",
    "# import json for json formatting\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rate treshhold\n",
    "rateThreshold = 0.1\n",
    "# print in-progress report\n",
    "printSwitch = True\n",
    "# Sets the naming standard\n",
    "sampleFolder = \"tiles\"\n",
    "resultsFolder= \"results\"\n",
    "# Set log file info\n",
    "logFolder = \"log\"\n",
    "logFileName = \"log.txt\"\n",
    "failedSamplePath = \"fails\"\n",
    "\n",
    "retrainedLabels = \"retrained_labels.txt\" ####\n",
    "retrainedGraph = \"retrained_graph.pb\"\n",
    "\n",
    "# Error messages:\n",
    "nameFinderError= \"File names cannot be read\"\n",
    "fileReadError = \"Couldn't read files\"\n",
    "\n",
    "\n",
    "# Report messages:\n",
    "saveToFileReport = \"Data saved to the file: \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# no helper function for this part yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes\n",
    "\n",
    "### The Classifier\n",
    "This class gets the images in the tiles folder and based on the trained model will classify them.\n",
    "In this case it will classify them as:\n",
    "    unifinished\n",
    "    scratches\n",
    "    holes\n",
    "    pass\n",
    "Those which fall in categories except pass will be stored in the log folder for further inspection.\n",
    "The extra inspection code has not been implemented yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # keep track of time\n",
    "        self.start_time = time.time()\n",
    "        # basic setup\n",
    "        self.logFolder = logFolder\n",
    "        self.sampleFolder= sampleFolder\n",
    "        self.logFolder = logFolder \n",
    "        self.logFileName = logFileName\n",
    "        self.retrainedLabels = retrainedLabels\n",
    "        self.retrainedGraph = retrainedGraph\n",
    "        self.failedSamplePath = failedSamplePath\n",
    "        self.rateThreshold = rateThreshold\n",
    "        \n",
    "        \n",
    "        # placeholders\n",
    "        self.samples = []\n",
    "        self.sampleNames = []\n",
    "        self.labels = []\n",
    "        self.rates = []\n",
    "        self.log = []\n",
    "        self.fails =  dict()\n",
    "        \n",
    "        # initiating the instance\n",
    "        Classifier.loadSamples(self)\n",
    "        Classifier.nameFinder(self)\n",
    "        Classifier.classifying(self)\n",
    "        Classifier.fileLogger(self)\n",
    "    \n",
    "    def nameFinder(self, folder=None):\n",
    "        if folder == None : folder = self.sampleFolder\n",
    "        if (not Classifier.folderCheck(self,folder)):\n",
    "            return    \n",
    "        # filters only the .jpg files from the folder\n",
    "        try:\n",
    "            files = [f for f in listdir(folder) if isfile(join(folder, f))]\n",
    "            self.sampleNames = [f for f in files if f.split(\".\")[1] == \"jpg\"]\n",
    "            if len(self.sampleNames == 0) : return False\n",
    "        except:\n",
    "            print (nameFinderError)\n",
    "\n",
    "    # Reads the sample files\n",
    "    def loadSamples(self, folder = None):\n",
    "        if folder == None : folder = self.sampleFolder\n",
    "        if (not Classifier.folderCheck(self,folder)):\n",
    "            return    \n",
    "        \n",
    "        # Loads files at ./tests folder to test based on the trained model \n",
    "        # only lists the .jpg files\n",
    "        # collects all file names\n",
    "        try:\n",
    "            files = [f for f in listdir(folder) if isfile(join(folder, f))]\n",
    "            # filters only the .jpg files\n",
    "            images = [f for f in files if f.split(\".\")[1] == \"jpg\"]\n",
    "            size = len(images)\n",
    "            for img in images:\n",
    "                newPath = folder+\"/\"+img\n",
    "                newSample = tf.gfile.FastGFile(newPath, 'rb').read()\n",
    "                self.samples.append(newSample)\n",
    "        except:\n",
    "            print (fileReadError)\n",
    "            \n",
    "    # Classifies the images\n",
    "    def classifying(self,sampleData = None, sampleNames= None):\n",
    "        if sampleData == None : sampleData = self.samples\n",
    "        if sampleNames == None : sampleNames = self.sampleNames    \n",
    "        if (len(sampleData) < 1  or\n",
    "            len(sampleNames) < 1 or\n",
    "            sampleData == None   or\n",
    "            sampleNames == None):\n",
    "            print (len(sampleData))\n",
    "            print (len(sampleNames))\n",
    "            print (\"failed\")\n",
    "            return False    \n",
    "        \n",
    "        \n",
    "        size = len(sampleData)\n",
    "        # Loads label file, strips off carriage return\n",
    "        label_lines = [line.rstrip() for line \n",
    "                       in tf.gfile.GFile(self.retrainedLabels)]\n",
    "        # Unpersists graph from file\n",
    "        with tf.gfile.FastGFile(self.retrainedGraph, 'rb') as f:\n",
    "            graph_def = tf.GraphDef()\n",
    "            graph_def.ParseFromString(f.read())\n",
    "            ####################################################\n",
    "            # just a hacky way to solve version discrpancies\n",
    "            # if using older versions of Tensorflow,\n",
    "            # remove this line!\n",
    "            del(graph_def.node[1].attr[\"dct_method\"])\n",
    "            ####################################################\n",
    "            _ = tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            # Feed the image_data as input to the graph and get first prediction\n",
    "            softmax_tensor = sess.graph.get_tensor_by_name('final_result:0')\n",
    "            \n",
    "            # iterating over iamges\n",
    "            for i in range (size):\n",
    "                print(\"{{{{{{{{{{{{{{{{{{{\",type(sampleData[i]))\n",
    "                print(len(sampleData[i]))\n",
    "                #for image_data_item in image_data:\n",
    "                predictions = sess.run(softmax_tensor, \\\n",
    "                         {'DecodeJpeg/contents:0': sampleData[i]})\n",
    "                # Sort to show labels of first prediction in order of confidence\n",
    "                top_k = predictions[0].argsort()[-len(predictions[0]):][::-1]\n",
    "                human_string = label_lines[top_k[0]]\n",
    "                score = predictions[0][top_k[0]]\n",
    "                \n",
    "                # update the scoreboard and labelboard\n",
    "                self.rates.append(score)\n",
    "                self.labels.append(human_string)\n",
    "                # print report during the process\n",
    "                if (printSwitch):\n",
    "                    print (\"smaple ID\", str(i))\n",
    "                    print('%s (score = %.2f)' % (human_string, score))\n",
    "                    #print('Correct answer: %s' %(sampleNames[i][:4]))\n",
    "                    print(\"------------------------------------\")\n",
    "                if (human_string != \"pass\" or score < rateThreshold):\n",
    "                    self.fails[sampleNames[i]] = human_string\n",
    "\n",
    "    def folderCheck(self,folder):\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "            log =  (Classifier.makingAFolder+ folder)\n",
    "            TileSampler.logger(self, log)\n",
    "            return False\n",
    "        else:\n",
    "            #print (\"pass\")\n",
    "            return True\n",
    "        \n",
    "    def logger(self, message, header = None):\n",
    "        timeVal = time.strftime(\"%H:%M:%S: \")\n",
    "        if type(message) == list:\n",
    "            size = len(message)\n",
    "            tag = \"size: #\"+ str(size)+ \"|\"\n",
    "            message.insert (0,tag)\n",
    "            message = \" \".join(message)\n",
    "        \n",
    "        if header != None:\n",
    "            message = header  + message\n",
    "        message = timeVal + message\n",
    "        self.log.append(message)\n",
    "    \n",
    "    # Generates the log in log folder \n",
    "    def fileLogger(self):\n",
    "        Classifier.report(self)\n",
    "        Classifier.saveToFile(self)\n",
    "        Classifier.saveFailSamples(self) \n",
    "        \n",
    "    # Prints a brief report during the process\n",
    "    def report(self):\n",
    "        finish_time = time.time()\n",
    "        ellapsed_time = finish_time - self.start_time\n",
    "        average_time = ellapsed_time / float(len(self.samples))\n",
    "        \n",
    "        # Print the final report\n",
    "        print ('Total time:', str(int(ellapsed_time)))\n",
    "        print ('Average time:', str(average_time)) \n",
    "        print (\"------------------------------------\")\n",
    "        print (\"Failed samples:\")\n",
    "        for fail in self.fails:\n",
    "            print (fail,\"\\t\",self.fails[fail])\n",
    "        print(\"------------------------------------\")\n",
    "    \n",
    "    def saveToFile(self):\n",
    "        folder = self.logFolder\n",
    "        # converts fails to json format\n",
    "        jsonData = json.dumps(self.fails)\n",
    "\n",
    "        # check if the log directory exist\n",
    "        if not exists(folder):\n",
    "            os.makedirs(folder)\n",
    "            \n",
    "        # generates the file name to save the log\n",
    "        date_string = time.strftime(\"_%H_%M\")\n",
    "        newName = folder+date_string+\".txt\"\n",
    "        print (\"newName: \",newName)\n",
    "        newPath = os.path.join (folder, newName)\n",
    "        print (\"newPath: \",newPath)\n",
    "        \n",
    "        # writes to file\n",
    "        log = open(newPath, \"w\")\n",
    "        log.write(str(jsonData))\n",
    "        log.close()\n",
    "        print (saveToFileReport,newPath)\n",
    "        logData = (saveToFileReport+newPath)\n",
    "        Classifier.logger(self, logData)\n",
    "        \n",
    "    def saveFailSamples(self):\n",
    "        for fail in self.fails:\n",
    "            failedSamplePath = self.sampleFolder+\"/\"+fail\n",
    "            name= fail.split(\".\")\n",
    "            targetPath = self.logFolder+\"/\"+name[0]+\"_\"+self.fails[fail]+\".jpg\"\n",
    "            copyfile(failedSamplePath, targetPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test\n",
    "This will run the classifier to classify images in the tiled folder and store rejected ones in the log folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File names cannot be read\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "13164\n",
      "smaple ID 0\n",
      "pass (score = 0.96)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "13387\n",
      "smaple ID 1\n",
      "pass (score = 0.86)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12940\n",
      "smaple ID 2\n",
      "pass (score = 0.98)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "13006\n",
      "smaple ID 3\n",
      "pass (score = 0.99)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12800\n",
      "smaple ID 4\n",
      "pass (score = 1.00)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12862\n",
      "smaple ID 5\n",
      "pass (score = 0.99)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12800\n",
      "smaple ID 6\n",
      "pass (score = 1.00)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "13217\n",
      "smaple ID 7\n",
      "pass (score = 0.97)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12642\n",
      "smaple ID 8\n",
      "pass (score = 0.99)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12998\n",
      "smaple ID 9\n",
      "pass (score = 0.99)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12682\n",
      "smaple ID 10\n",
      "pass (score = 0.98)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12514\n",
      "smaple ID 11\n",
      "pass (score = 0.99)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12824\n",
      "smaple ID 12\n",
      "pass (score = 0.71)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12685\n",
      "smaple ID 13\n",
      "pass (score = 0.60)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12852\n",
      "smaple ID 14\n",
      "pass (score = 0.76)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "13005\n",
      "smaple ID 15\n",
      "pass (score = 0.95)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "13479\n",
      "smaple ID 16\n",
      "pass (score = 0.57)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "13110\n",
      "smaple ID 17\n",
      "pass (score = 1.00)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "13789\n",
      "smaple ID 18\n",
      "pass (score = 0.98)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12824\n",
      "smaple ID 19\n",
      "pass (score = 0.98)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12736\n",
      "smaple ID 20\n",
      "pass (score = 0.99)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12549\n",
      "smaple ID 21\n",
      "pass (score = 1.00)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "13092\n",
      "smaple ID 22\n",
      "pass (score = 1.00)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12716\n",
      "smaple ID 23\n",
      "pass (score = 0.79)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12561\n",
      "smaple ID 24\n",
      "pass (score = 0.90)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "13033\n",
      "smaple ID 25\n",
      "pass (score = 0.51)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12370\n",
      "smaple ID 26\n",
      "pass (score = 1.00)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "13115\n",
      "smaple ID 27\n",
      "pass (score = 0.98)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12911\n",
      "smaple ID 28\n",
      "pass (score = 0.96)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12705\n",
      "smaple ID 29\n",
      "pass (score = 0.84)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12713\n",
      "smaple ID 30\n",
      "pass (score = 0.77)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "13185\n",
      "smaple ID 31\n",
      "pass (score = 0.89)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "13192\n",
      "smaple ID 32\n",
      "pass (score = 0.91)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12686\n",
      "smaple ID 33\n",
      "pass (score = 0.98)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "13370\n",
      "smaple ID 34\n",
      "pass (score = 0.63)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "13004\n",
      "smaple ID 35\n",
      "pass (score = 0.98)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "13754\n",
      "smaple ID 36\n",
      "pass (score = 0.99)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12973\n",
      "smaple ID 37\n",
      "pass (score = 0.98)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12810\n",
      "smaple ID 38\n",
      "pass (score = 0.91)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12693\n",
      "smaple ID 39\n",
      "pass (score = 1.00)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12729\n",
      "smaple ID 40\n",
      "pass (score = 0.99)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12591\n",
      "smaple ID 41\n",
      "pass (score = 0.99)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12709\n",
      "smaple ID 42\n",
      "pass (score = 0.99)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12392\n",
      "smaple ID 43\n",
      "pass (score = 0.84)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12836\n",
      "smaple ID 44\n",
      "pass (score = 0.91)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12665\n",
      "smaple ID 45\n",
      "pass (score = 0.96)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12390\n",
      "smaple ID 46\n",
      "pass (score = 0.99)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12465\n",
      "smaple ID 47\n",
      "pass (score = 0.96)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12583\n",
      "smaple ID 48\n",
      "pass (score = 0.88)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12650\n",
      "smaple ID 49\n",
      "scratches (score = 0.63)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12560\n",
      "smaple ID 50\n",
      "pass (score = 0.97)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12974\n",
      "smaple ID 51\n",
      "pass (score = 0.99)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12929\n",
      "smaple ID 52\n",
      "pass (score = 0.58)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "13226\n",
      "smaple ID 53\n",
      "pass (score = 0.68)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12516\n",
      "smaple ID 54\n",
      "pass (score = 0.99)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "13026\n",
      "smaple ID 55\n",
      "scratches (score = 0.40)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12669\n",
      "smaple ID 56\n",
      "pass (score = 0.99)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12751\n",
      "smaple ID 57\n",
      "holes (score = 0.99)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12365\n",
      "smaple ID 58\n",
      "pass (score = 0.99)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12325\n",
      "smaple ID 59\n",
      "pass (score = 1.00)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "13101\n",
      "smaple ID 60\n",
      "pass (score = 0.93)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12120\n",
      "smaple ID 61\n",
      "pass (score = 0.73)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "13106\n",
      "smaple ID 62\n",
      "pass (score = 0.99)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12721\n",
      "smaple ID 63\n",
      "scratches (score = 0.72)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12472\n",
      "smaple ID 64\n",
      "pass (score = 0.95)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12149\n",
      "smaple ID 65\n",
      "pass (score = 0.89)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "14243\n",
      "smaple ID 66\n",
      "unifinished (score = 0.90)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12754\n",
      "smaple ID 67\n",
      "pass (score = 0.99)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12697\n",
      "smaple ID 68\n",
      "pass (score = 0.49)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "13028\n",
      "smaple ID 69\n",
      "pass (score = 0.99)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12221\n",
      "smaple ID 70\n",
      "pass (score = 0.98)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "13262\n",
      "smaple ID 71\n",
      "pass (score = 0.98)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12441\n",
      "smaple ID 72\n",
      "pass (score = 0.99)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smaple ID 73\n",
      "pass (score = 0.99)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12257\n",
      "smaple ID 74\n",
      "pass (score = 0.98)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12666\n",
      "smaple ID 75\n",
      "pass (score = 0.99)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12213\n",
      "smaple ID 76\n",
      "pass (score = 0.98)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12746\n",
      "smaple ID 77\n",
      "scratches (score = 0.61)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12902\n",
      "smaple ID 78\n",
      "pass (score = 1.00)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12498\n",
      "smaple ID 79\n",
      "pass (score = 1.00)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "13204\n",
      "smaple ID 80\n",
      "pass (score = 0.67)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12392\n",
      "smaple ID 81\n",
      "pass (score = 1.00)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12520\n",
      "smaple ID 82\n",
      "pass (score = 0.97)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12856\n",
      "smaple ID 83\n",
      "pass (score = 0.99)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "13077\n",
      "smaple ID 84\n",
      "pass (score = 0.99)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12676\n",
      "smaple ID 85\n",
      "pass (score = 0.99)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "13307\n",
      "smaple ID 86\n",
      "pass (score = 0.99)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12779\n",
      "smaple ID 87\n",
      "pass (score = 0.99)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "13437\n",
      "smaple ID 88\n",
      "pass (score = 0.95)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "14077\n",
      "smaple ID 89\n",
      "pass (score = 0.98)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "13028\n",
      "smaple ID 90\n",
      "pass (score = 0.99)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "13142\n",
      "smaple ID 91\n",
      "pass (score = 0.99)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12835\n",
      "smaple ID 92\n",
      "pass (score = 0.96)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "13139\n",
      "smaple ID 93\n",
      "pass (score = 0.98)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12702\n",
      "smaple ID 94\n",
      "pass (score = 1.00)\n",
      "------------------------------------\n",
      "{{{{{{{{{{{{{{{{{{{ <class 'bytes'>\n",
      "12727\n",
      "smaple ID 95\n",
      "pass (score = 1.00)\n",
      "------------------------------------\n",
      "Total time: 27\n",
      "Average time: 0.2860010440150897\n",
      "------------------------------------\n",
      "Failed samples:\n",
      "tile_54_000.jpg \t scratches\n",
      "tile_5_000.jpg \t scratches\n",
      "tile_61_000.jpg \t holes\n",
      "tile_67_000.jpg \t scratches\n",
      "tile_6_000.jpg \t unifinished\n",
      "tile_7_000.jpg \t scratches\n",
      "------------------------------------\n",
      "newName:  log_16_04.txt\n",
      "newPath:  log\\log_16_04.txt\n",
      "Data saved to the file:  log\\log_16_04.txt\n"
     ]
    }
   ],
   "source": [
    "classify = Classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A histogram of the rates for every sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(classify.rates)\n",
    "plt.title(\"Gaussian Histogram\")\n",
    "plt.xlabel(\"Scores\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "fig = plt.gcf()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detailed report of the rejected samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range (len(classify.labels)):\n",
    "    print (i, \"\\t\", classify.labels[i][:5], \"\\t\",classify.rates[i], \"\\t\", classify.sampleNames[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 1024\n",
    "ones = 10\n",
    "dataSet = np.zeros(size**2)\n",
    "#dataSet[-size//10:] = 1\n",
    "dataSet[-ones:] = 1\n",
    "\n",
    "np.random.shuffle(dataSet)\n",
    "dataSet = dataSet.reshape((size,size))\n",
    "dataSet.shape\n",
    "print (np.sum(dataSet))\n",
    "print(dataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "depth = 0\n",
    "def searchTree(dataSet,depth):\n",
    "    resolution = 32\n",
    "    depth += 1\n",
    "    if (np.sum(dataSet) >=1) and dataSet.shape[0] == resolution:\n",
    "        # check if this is an acceptable case\n",
    "        print (\"Sum: \", np.sum(dataSet))\n",
    "        return True\n",
    "    if (dataSet.shape[0] <= resolution):\n",
    "        return False\n",
    "    \n",
    "    newRow = int(dataSet.shape[0]/2)\n",
    "    newCol = int(dataSet.shape[1]/2)\n",
    "    \n",
    "    set1 = dataSet[:newRow,: newCol]\n",
    "    set2 = dataSet [:newRow, newCol:]\n",
    "    set3 = dataSet [newRow:,:newCol]\n",
    "    set4 = dataSet [newRow:, newCol:]\n",
    "    newDataSet = [set1,set2,set3,set4]\n",
    "    \n",
    "    for data in newDataSet:\n",
    "        searchTree(data,depth)\n",
    "    \n",
    "searchTree(dataSet,depth)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def slicer():\n",
    "    imagePath = \"tiles/sensorData.JPG\"\n",
    "    sensorPath = \"tiles/\"\n",
    "    names = []\n",
    "    img = cv2.imread(imagePath)\n",
    "    print(\"--------------------\", img.shape)\n",
    "    # cleanup the folder\n",
    "    for file in os.listdir(sensorPath):\n",
    "        # if file == \"capture.jpg\":\n",
    "        #     print (\"++++++++++++++++++++++++ Capture\", file)\n",
    "\n",
    "        filePath = os.path.join(sensorPath, file)\n",
    "        try:\n",
    "            if os.path.isfile(filePath) :\n",
    "                print(filePath)\n",
    "                os.unlink(filePath)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    h,w,_ = img.shape\n",
    "    sampleSize = 500\n",
    "    r = int(h/sampleSize)\n",
    "    c = int(w/sampleSize)\n",
    "    for i in range(c):\n",
    "        for j in range(r-1):\n",
    "            crop_img = img[sampleSize*j:sampleSize*(j+1), sampleSize*i:sampleSize*(i+1)]\n",
    "            name = sensorPath+str(i)+\"-\"+str(j)+\".jpg\"\n",
    "            cv2.imwrite(name,crop_img)\n",
    "            names.append(name)\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePath = \"sample.jpg\"\n",
    "url = \"https://image.ibb.co/jEcBub/GOPR2856.jpg\"\n",
    "img = urllib.request.urlretrieve(url, imagePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sliceToFour(imagePath):\n",
    "    # load the image\n",
    "    img = cv2.imread(imagePath)\n",
    "    h, w, _ = img.shape\n",
    "    \n",
    "    # dividing image to 4 sections\n",
    "    r = int(h / 2)\n",
    "    c = int(w / 2)\n",
    "    \n",
    "    img0 = img[:r, :c]\n",
    "    img1 = img[:r, c:]\n",
    "    img2 = img[r:, :c]\n",
    "    img3 = img[r:, c:]\n",
    "    \n",
    "    imgs = [img0, img1, img2, img3]\n",
    "    \n",
    "    return (imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pics = sliceToFour(imagePath)\n",
    "cv2.imshow('image',pics[0])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(sampleData = None):\n",
    "    labels = []\n",
    "    status = []\n",
    "    size = len(sampleData)\n",
    "    # Loads label file, strips off carriage return\n",
    "    label_lines = [line.rstrip() for line \n",
    "                   in tf.gfile.GFile(retrainedLabels)]\n",
    "    # Unpersists graph from file\n",
    "    with tf.gfile.FastGFile(retrainedGraph, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        ####################################################\n",
    "        # just a hacky way to solve version discrpancies\n",
    "        # if using older versions of Tensorflow,\n",
    "        # remove this line!\n",
    "        del(graph_def.node[1].attr[\"dct_method\"])\n",
    "        ####################################################\n",
    "        _ = tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        # Feed the image_data as input to the graph and get first prediction\n",
    "        softmax_tensor = sess.graph.get_tensor_by_name('final_result:0')\n",
    "\n",
    "        # iterating over iamges\n",
    "        for i in range (size):\n",
    "        #for image_data_item in image_data:\n",
    "            predictions = sess.run(softmax_tensor, \\\n",
    "                     {'DecodeJpeg/contents:0': sampleData[i]})\n",
    "            # Sort to show labels of first prediction in order of confidence\n",
    "            top_k = predictions[0].argsort()[-len(predictions[0]):][::-1]\n",
    "            human_string = label_lines[top_k[0]]\n",
    "            score = predictions[0][top_k[0]]\n",
    "\n",
    "            # print report during the process\n",
    "            if (printSwitch):\n",
    "                print (\"smaple ID\", str(i))\n",
    "                print('%s (score = %.2f)' % (human_string, score))\n",
    "                #print('Correct answer: %s' %(sampleNames[i][:4]))\n",
    "                print(\"------------------------------------\")\n",
    "            if (human_string != \"pass\" or score < rateThreshold):\n",
    "                status.append(\"fail\")\n",
    "            else:\n",
    "                status.append(\"pass\")\n",
    "\n",
    "            labels.append(human_string)\n",
    "    return (labels, status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++++++\n",
      "1 1920 2560\n",
      "Session started\n",
      "Running 0 image\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (960, 1280, 3) for Tensor 'DecodeJpeg/contents:0', which has shape '()'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-2cc10c06f4d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimagePath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[0msearchTree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m \u001b[0msearchImageQuad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-2cc10c06f4d9>\u001b[0m in \u001b[0;36msearchImageQuad\u001b[1;34m()\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimagePath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimagePath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m     \u001b[0msearchTree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[0msearchImageQuad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-2cc10c06f4d9>\u001b[0m in \u001b[0;36msearchTree\u001b[1;34m(image, depth)\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Running {} image\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m             \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoftmax_tensor\u001b[0m\u001b[1;33m,\u001b[0m                              \u001b[1;33m{\u001b[0m\u001b[1;34m'DecodeJpeg/contents:0'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mimgs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m             \u001b[1;31m# Sort to show labels of first prediction in order of confidence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[0mtop_k\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 \u001b[1;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m                 \u001b[1;34m'which has shape %r'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m   1101\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (960, 1280, 3) for Tensor 'DecodeJpeg/contents:0', which has shape '()'"
     ]
    }
   ],
   "source": [
    "def searchTree(image,depth):\n",
    "    \n",
    "    resolution = 64\n",
    "    depth += 1\n",
    "    h, w, _ = image.shape\n",
    "    print(\"+++++++++++\")\n",
    "    print (depth, h, w)\n",
    "    \n",
    "\n",
    "    \n",
    "#     #Format for the Mul:0 Tensor\n",
    "#     img2= cv2.resize(img2,dsize=(299,299), interpolation = cv2.INTER_CUBIC)\n",
    "#     #Numpy array\n",
    "#     np_image_data = np.asarray(img2)\n",
    "#     #maybe insert float convertion here - see edit remark!\n",
    "#     np_final = np.expand_dims(np_image_data,axis=0)\n",
    "\n",
    "#     #now feeding it into the session:\n",
    "#     #[... initialization of session and loading of graph etc]\n",
    "#     predictions = sess.run(softmax_tensor,\n",
    "#                                {'Mul:0': np_final})\n",
    "    \n",
    "    \n",
    "    # dividing image to 4 sections\n",
    "    r = int(h / 2)\n",
    "    c = int(w / 2)\n",
    "    \n",
    "    img0 = image[:r, :c]\n",
    "    img1 = image[:r, c:]\n",
    "    img2 = image[r:, :c]\n",
    "    img3 = image[r:, c:]\n",
    "    \n",
    "    imgs = [img0,img1,img2,img3]\n",
    "    originalImgs = [img0,img1,img2,img3]\n",
    "    \n",
    "    ########################################################\n",
    "    # To do: look at the next webpage and put this whole \n",
    "    # recursive search inside the tf session\n",
    "    ########################################################\n",
    "    \n",
    "    \n",
    "#     img0= cv2.resize(image[:r, :c],dsize=(r,r), interpolation = cv2.INTER_CUBIC)\n",
    "#     img1= cv2.resize(image[:r, c:],dsize=(r,r), interpolation = cv2.INTER_CUBIC)\n",
    "#     img2= cv2.resize(image[r:, :c],dsize=(r,r), interpolation = cv2.INTER_CUBIC)\n",
    "#     img3= cv2.resize(image[r:, c:],dsize=(r,r), interpolation = cv2.INTER_CUBIC)\n",
    "#     img0 = np.asarray(img0)\n",
    "#     img0 = np.expand_dims(img0,axis=0)\n",
    "#     img1 = np.asarray(img1)\n",
    "#     img1 = np.expand_dims(img1,axis=0)\n",
    "#     img2 = np.asarray(img2)\n",
    "#     img2 = np.expand_dims(img2,axis=0)\n",
    "#     img3 = np.asarray(img3)\n",
    "#     img3 = np.expand_dims(img3,axis=0)\n",
    "    \n",
    "    #imgs = [img0,img1,img2,img3]\n",
    "    tags = []\n",
    "    status = []\n",
    "    \n",
    "    # Loads label file, strips off carriage return\n",
    "    label_lines = [line.rstrip() for line \n",
    "                   in tf.gfile.GFile(retrainedLabels)]\n",
    "    \n",
    "    with tf.gfile.FastGFile(retrainedGraph, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        ####################################################\n",
    "        # just a hacky way to solve version discrpancies\n",
    "        # if using older versions of Tensorflow,\n",
    "        # remove this line!\n",
    "        del(graph_def.node[1].attr[\"dct_method\"])\n",
    "        ####################################################\n",
    "        _ = tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        softmax_tensor = sess.graph.get_tensor_by_name('final_result:0')\n",
    "        print(\"Session started\")\n",
    "        for i in range(4):\n",
    "            print(\"Running {} image\".format(i))\n",
    "            predictions = sess.run(softmax_tensor, \\\n",
    "                             {'DecodeJpeg/contents:0': imgs[i]})\n",
    "            # Sort to show labels of first prediction in order of confidence\n",
    "            top_k = predictions[0].argsort()[-len(predictions[0]):][::-1]\n",
    "            human_string = label_lines[top_k[0]]\n",
    "            score = predictions[0][top_k[0]]\n",
    "            status.append(human_string)\n",
    "        \n",
    "    for i in range(4):\n",
    "        if (status[i] !=\"pass\") and w <= resolution:\n",
    "            print (\"Catch it: \", tags[i])\n",
    "            return True\n",
    "\n",
    "        if (w <= resolution):\n",
    "            return False\n",
    "    \n",
    "    for i in range(4):\n",
    "        if (status[i] != \"pass\"):\n",
    "            searchTree(originalImgs[i],depth)\n",
    "\n",
    "def searchImageQuad():\n",
    "    imagePath = \"sample.jpg\"\n",
    "    url = \"https://image.ibb.co/jEcBub/GOPR2856.jpg\"\n",
    "    img = urllib.request.urlretrieve(url, imagePath)\n",
    "    img = cv2.imread(imagePath)\n",
    "    searchTree(img,0)\n",
    "searchImageQuad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePath = \"sample.jpg\"\n",
    "url = \"https://image.ibb.co/jEcBub/GOPR2856.jpg\"\n",
    "img = urllib.request.urlretrieve(url, imagePath)\n",
    "\n",
    "img_ = cv2.imread(imagePath)\n",
    "r = img_.shape[0]\n",
    "c = img_.shape[1]\n",
    "img2 = cv2.resize(img_,dsize=(r,c), interpolation = cv2.INTER_CUBIC)\n",
    "#Numpy array\n",
    "np_image_data = np.asarray(img2)\n",
    "np_image_data=cv2.normalize(np_image_data.astype('float'), None, -0.5, .5, cv2.NORM_MINMAX)\n",
    "#maybe insert float convertion here - see edit remark!\n",
    "newSample = np.expand_dims(np_image_data,axis=0)\n",
    "newSample = tf.gfile.FastGFile(imagePath, 'rb').read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unifinished 1\n",
      "unifinished 2\n",
      "pass 3\n",
      "pass 4\n"
     ]
    }
   ],
   "source": [
    "size = 4\n",
    "image = cv2.imread(imagePath)\n",
    "label_lines = [line.rstrip() for line \n",
    "                   in tf.gfile.GFile(retrainedLabels)]\n",
    "# Unpersists graph from file\n",
    "with tf.gfile.FastGFile(retrainedGraph, 'rb') as f:\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "    ####################################################\n",
    "    # just a hacky way to solve version discrpancies\n",
    "    # if using older versions of Tensorflow,\n",
    "    # remove this line!\n",
    "    del(graph_def.node[1].attr[\"dct_method\"])\n",
    "    ####################################################\n",
    "    _ = tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Feed the image_data as input to the graph and get first prediction\n",
    "    softmax_tensor = sess.graph.get_tensor_by_name('final_result:0')\n",
    "    \n",
    "    h,w,_ = image.shape\n",
    "    r = int(h / 2)\n",
    "    c = int(w / 2)\n",
    "\n",
    "    img0 = image[:r, :c]\n",
    "    img1 = image[:r, c:]\n",
    "    img2 = image[r:, :c]\n",
    "    img3 = image[r:, c:]\n",
    "\n",
    "    imgs = [img0,img1,img2,img3]\n",
    "    cv2.imwrite( \"tfImg0.jpg\", img0)\n",
    "    cv2.imwrite( \"tfImg1.jpg\", img1)\n",
    "    cv2.imwrite( \"tfImg2.jpg\", img2)\n",
    "    cv2.imwrite( \"tfImg3.jpg\", img3)\n",
    "    \n",
    "    tfImgs = []\n",
    "    tfImgs.append(tf.gfile.FastGFile(\"tfImg0.jpg\", 'rb').read())\n",
    "    tfImgs.append(tf.gfile.FastGFile(\"tfImg1.jpg\", 'rb').read())\n",
    "    tfImgs.append(tf.gfile.FastGFile(\"tfImg2.jpg\", 'rb').read())\n",
    "    tfImgs.append(tf.gfile.FastGFile(\"tfImg3.jpg\", 'rb').read())\n",
    "    counter = 0\n",
    "    \n",
    "    # iterating over iamges\n",
    "    for img in tfImgs:\n",
    "        counter += 1\n",
    "        #for image_data_item in image_data:\n",
    "        predictions = sess.run(softmax_tensor, \\\n",
    "                 {'DecodeJpeg/contents:0': img})\n",
    "        # Sort to show labels of first prediction in order of confidence\n",
    "        top_k = predictions[0].argsort()[-len(predictions[0]):][::-1]\n",
    "        human_string = label_lines[top_k[0]]\n",
    "        score = predictions[0][top_k[0]]\n",
    "        print (human_string, counter)\n",
    "    return ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
