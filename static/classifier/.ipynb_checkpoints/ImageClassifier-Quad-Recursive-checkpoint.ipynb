{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classifier Module\n",
    "\n",
    "ArdavanBidgoli <br />\n",
    "CMU School of Architecture <br />\n",
    "Robotic Plastering Project <br />\n",
    "Feedback-loop image classifier <br />\n",
    "Tested with/for: <br />\n",
    "Tensorflow 0.12.1 <br />\n",
    "OpenCV 3.2.0-dev <br />\n",
    "this code has been inspired by:\n",
    "https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/index.html?index=../../index#4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Tensorflow\n",
    "import tensorflow as tf\n",
    "# Importing matplotlib and Numpy for image processing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline\n",
    "\n",
    "# Import libraries for:\n",
    "# System read and write, Checking object types, Time keeping\n",
    "import sys\n",
    "import time\n",
    "from shutil import copyfile\n",
    "import cv2\n",
    "# import os.path methods for file manipulation on the drive\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join, exists\n",
    "import copy\n",
    "# import json for json formatting\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rate treshhold\n",
    "rateThreshold = 0.1\n",
    "# print in-progress report\n",
    "printSwitch = True\n",
    "# Sets the naming standard\n",
    "sampleFolder = \"tiles\"\n",
    "resultsFolder= \"results\"\n",
    "# Set log file info\n",
    "logFolder = \"log\"\n",
    "logFileName = \"log.txt\"\n",
    "failedSamplePath = \"fails\"\n",
    "\n",
    "retrainedLabels = \"retrained_labels.txt\" ####\n",
    "retrainedGraph = \"retrained_graph.pb\"\n",
    "\n",
    "# Error messages:\n",
    "nameFinderError= \"File names cannot be read\"\n",
    "fileReadError = \"Couldn't read files\"\n",
    "\n",
    "\n",
    "# Report messages:\n",
    "saveToFileReport = \"Data saved to the file: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imagePath = \"sample.jpg\"\n",
    "url = \"https://image.ibb.co/jEcBub/GOPR2856.jpg\"\n",
    "img = urllib.request.urlretrieve(url, imagePath)\n",
    "img_ = cv2.imread(imagePath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imagePath = \"sample.jpg\"\n",
    "url = \"https://image.ibb.co/jEcBub/GOPR2856.jpg\"\n",
    "img = urllib.request.urlretrieve(url, imagePath)\n",
    "img = cv2.imread(imagePath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0|1|1\n"
     ]
    }
   ],
   "source": [
    "root = TreeNode(\"0\",index = 0)\n",
    "for i in range(4):\n",
    "    tmpNode = TreeNode(root.image+\"|\"+str(i),index = i, parent = root)\n",
    "    for j in range(4):\n",
    "        TreeNode(tmpNode.image+\"|\"+str(j),index = j,parent = tmpNode)\n",
    "    \n",
    "print(root.children[1].children[1].image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode_():\n",
    "    # initializing the nodes\n",
    "    def __init__(self, image,index, parent = None):\n",
    "        # children must be a set\n",
    "        if parent == None:\n",
    "            self.parent = None\n",
    "        else:\n",
    "            self.parent = parent\n",
    "            self.parent.children[index] = self\n",
    "\n",
    "        self.image = image\n",
    "        self.children = [None for i in range(4)]\n",
    "\n",
    "        if (self.parent):\n",
    "            self.index = self.parent.index+\"|\" +str(index) \n",
    "        else:\n",
    "            self.index = str(index)\n",
    "\n",
    "    def __str__(self):\n",
    "        return (self.index)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode(object):\n",
    "    def __init__(self, \n",
    "                 image,\n",
    "                 tag = None,\n",
    "                 label= None,\n",
    "                 index= None,\n",
    "                 parent = None):\n",
    "        # first set the tag\n",
    "        self.image = image\n",
    "        if parent == None:\n",
    "            self.parent = None\n",
    "            self.index = str(index)\n",
    "            \n",
    "        else:\n",
    "            if index == None:\n",
    "                return False\n",
    "            self.parent = parent\n",
    "            self.parent.children[index] = self\n",
    "        \n",
    "        if (self.parent):\n",
    "            self.index = self.parent.index+\"|\"+str(index)\n",
    "        if label == None:\n",
    "            self.label = \"pass\"\n",
    "        else:\n",
    "            self.label = label\n",
    "        if tag == None:\n",
    "            self.tag = \"\"\n",
    "        else:\n",
    "            self.tag = tag\n",
    "        self.children = [None for i in range(4)]\n",
    "        \n",
    "    def __str__(self):\n",
    "        return self.index\n",
    "    \n",
    "    def __hash__ (self):\n",
    "        return (hash(self.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runing sess\n",
      "Depth#0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "GraphDef cannot be larger than 2GB.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-148-d02b653d442f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[0mtime0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mtime0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-148-d02b653d442f>\u001b[0m in \u001b[0;36mclassifier\u001b[1;34m()\u001b[0m\n\u001b[0;32m     93\u001b[0m                     \u001b[0mquadSearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mquadSearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[0mtime0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-148-d02b653d442f>\u001b[0m in \u001b[0;36mquadSearch\u001b[1;34m(image, treeNode, depth)\u001b[0m\n\u001b[0;32m     71\u001b[0m                 \u001b[0mcounter\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[1;31m#for image_data_item in image_data:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m                 \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoftmax_tensor\u001b[0m\u001b[1;33m,\u001b[0m                          \u001b[1;33m{\u001b[0m\u001b[1;34m'DecodeJpeg/contents:0'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtfImgs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m                 \u001b[1;31m# Sort to show labels of first prediction in order of confidence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m                 \u001b[0mtop_k\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1124\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1321\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1295\u001b[0m                 run_metadata):\n\u001b[0;32m   1296\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1297\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1298\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1299\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1351\u001b[0m         graph_def, self._current_version = self._graph._as_graph_def(\n\u001b[0;32m   1352\u001b[0m             \u001b[0mfrom_version\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_current_version\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1353\u001b[1;33m             add_shapes=self._add_shapes)\n\u001b[0m\u001b[0;32m   1354\u001b[0m         \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_as_graph_def\u001b[1;34m(self, from_version, add_shapes)\u001b[0m\n\u001b[0;32m   2444\u001b[0m           \u001b[0mbytesize\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mByteSize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2445\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mbytesize\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m<<\u001b[0m \u001b[1;36m31\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mbytesize\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2446\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"GraphDef cannot be larger than 2GB.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2447\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_functions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2448\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: GraphDef cannot be larger than 2GB."
     ]
    }
   ],
   "source": [
    "def classifier():\n",
    "    size = 4\n",
    "    label_lines = [line.rstrip() for line \n",
    "                   in tf.gfile.GFile(retrainedLabels)]\n",
    "    \n",
    "    # Unpersists graph from file\n",
    "    with tf.gfile.FastGFile(retrainedGraph, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        ####################################################\n",
    "        # just a hacky way to solve version discrpancies\n",
    "        # if using older versions of Tensorflow,\n",
    "        # remove this line!\n",
    "        del(graph_def.node[1].attr[\"dct_method\"])\n",
    "        ####################################################\n",
    "        _ = tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        print(\"Runing sess\")\n",
    "        # Feed the image_data as input to the graph and get first prediction\n",
    "        softmax_tensor = sess.graph.get_tensor_by_name('final_result:0')\n",
    "        \n",
    "        image = cv2.imread(imagePath)\n",
    "        root = TreeNode(image,index = 0)\n",
    "        \n",
    "        def quadSearch(image, treeNode , depth):\n",
    "            \n",
    "            parent = treeNode\n",
    "            print(\"Depth#{}\".format(depth))\n",
    "            resolution = 32\n",
    "            depth += 1\n",
    "            \n",
    "            labels = []\n",
    "            status = []\n",
    "            \n",
    "            h,w,_ = image.shape\n",
    "            r = int(h / 2)\n",
    "            c = int(w / 2)\n",
    "            if r < resolution:\n",
    "                return False\n",
    "            \n",
    "            img0 = image[:r, :c]\n",
    "            img1 = image[:r, c:]\n",
    "            img2 = image[r:, :c]\n",
    "            img3 = image[r:, c:]\n",
    "            \n",
    "            \n",
    "            imgs = [img0,img1,img2,img3]\n",
    "            \n",
    "            nodes = []\n",
    "            for i in range(4):\n",
    "                nodes.append(TreeNode(imgs[i],index = i, parent = parent))\n",
    "            \n",
    "                \n",
    "                \n",
    "            cv2.imwrite( \"tfImg0.jpg\", img0)\n",
    "            cv2.imwrite( \"tfImg1.jpg\", img1)\n",
    "            cv2.imwrite( \"tfImg2.jpg\", img2)\n",
    "            cv2.imwrite( \"tfImg3.jpg\", img3)\n",
    "\n",
    "            tfImgs = []\n",
    "            tfImgs.append(tf.gfile.FastGFile(\"tfImg0.jpg\", 'rb').read())\n",
    "            tfImgs.append(tf.gfile.FastGFile(\"tfImg1.jpg\", 'rb').read())\n",
    "            tfImgs.append(tf.gfile.FastGFile(\"tfImg2.jpg\", 'rb').read())\n",
    "            tfImgs.append(tf.gfile.FastGFile(\"tfImg3.jpg\", 'rb').read())\n",
    "            counter = 0\n",
    "\n",
    "            # iterating over iamges\n",
    "            for i in range(4):\n",
    "                \n",
    "                counter += 1\n",
    "                #for image_data_item in image_data:\n",
    "                predictions = sess.run(softmax_tensor, \\\n",
    "                         {'DecodeJpeg/contents:0': tfImgs[i]})\n",
    "                # Sort to show labels of first prediction in order of confidence\n",
    "                top_k = predictions[0].argsort()[-len(predictions[0]):][::-1]\n",
    "                human_string = label_lines[top_k[0]]\n",
    "                score = predictions[0][top_k[0]]\n",
    "                thisStatus = \"pass\"\n",
    "                if (human_string != \"pass\" or score < rateThreshold):\n",
    "                    thisStatus = \"fail\"\n",
    "                    print (human_string, counter)\n",
    "                    o = str(int(random.randint(1,9)))\n",
    "                    date_string = str(depth)+o+\"_\"+human_string+time.strftime(\"_%M_%S\")+\".jpg\"\n",
    "                    #cv2.imwrite(date_string, imgs[i])\n",
    "                    \n",
    "                status.append(thisStatus)\n",
    "                labels.append(human_string)\n",
    "            \n",
    "            for i in range(4):\n",
    "                if (status[i] != \"pass\" and imgs[i].shape[0] > resolution):\n",
    "                    nodes[i].label = status[i]\n",
    "                    nodes[i].tag = human_string\n",
    "                    quadSearch(imgs[i],nodes[i], depth)\n",
    "            return (root)\n",
    "        return (quadSearch(image,root,0))\n",
    "        \n",
    "time0 = time.time()\n",
    "graph = classifier()\n",
    "print(time.time()-time0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(graph.children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = graph.children[0].children[3].children[3].children[3].image\n",
    "print(graph.children[0].children[3].children[3].children[3].label)\n",
    "cv2.imshow(\"image\", image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myGraph = copy.deepcopy(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bfsOrder(graph):\n",
    "  result= []\n",
    "  stack = [graph]\n",
    "  # iteratively going over the leaves\n",
    "  while (len(stack) != 0 ):\n",
    "    tmpNode = stack[0]\n",
    "    stack = stack[1:]\n",
    "    result.append(tmpNode.index)\n",
    "    first = tmpNode.children[0]\n",
    "    second = tmpNode.children[1]\n",
    "    third = tmpNode.children[2]\n",
    "    forth = tmpNode.children[3]\n",
    "    #print(first.index, second.index, third.index, forth.index)\n",
    "    if first != None and first.label == \"fail\":\n",
    "      stack.append(first)\n",
    "    if second != None and second.label == \"fail\":\n",
    "      stack.append(second)\n",
    "    if third != None and third.label == \"fail\":\n",
    "      stack.append(third)\n",
    "    if forth != None and forth.label == \"fail\":\n",
    "      stack.append(forth)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bfsOrder(myGraph)\n",
    "myGraph.children[0].tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
